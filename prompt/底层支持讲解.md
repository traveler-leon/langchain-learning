
在llm中，通常输入会被我们称之为prompt，而在langchain中，提供了一种定义prompt的方式，就是事先会定义模板，然后开放部分变量让用户在实际使用时传入
这种定义一部分开放一部分的模板形式在langchain被称为prompt template，而prompt template生产出来的内容叫做prompt value，prompt value和llm需要的区别在于
可以提供字符串和message的互转

下面就讲讲langchain对于prompt  template的底层支持，底层是由BasePromptTemplate
## BasePromptTemplate
prompt template底层由BasePromptTemplate支持
BasePromptTemplate提供了一些基础能力的支持
	1. 变量保存
	2. 变量类型
	3. 输出解析
	4. 局部变量
	5. metadata
	6. tags
	
1. 校验输入变量
	1.1.输入变量不是一个字典，且只有一个的话，就会将input_variables中保存的变量名拿出来，组成一个字典   
	1.2 如果传入的是一个字典，如果字典和保存在input_variables中有差异，则报错。   
	1.3 返回校验后的输入字典   
	
2. 模板实例化
    2.1 校验config   
	2.2 校验输入变量    
	2.3 格式化模板（交给子类）   
	
3. 局部变量化
	2.1 将局部变量从input_variables提出，更新input_variables    
	
4. 转为dict
5. 保存到本地（只支持json 和yaml ）    

## 思考
在这个底层类中